\chapter{ معیارهای ارزیابی پیشین و پیشنهادی}\label{Chap:Chap4}
\minitoc
ارزیابی مدل‌های مولد به تنهایی چالش بوده و پژوهش‌های زیادی روی این موضوع انجام شده است.
در این فصل معیار‌های ارزیابی پیشین تشریح می‌شود، مشکلات آنها بررسی شده و معیار‌های جدیدی برای ارزیابی  معرفی می‌شود.
\section{مقدمه}
از بین معیار‌های مورد استفاده در پژوهش‌های پیشین، دسته‌ای از معیارها فقط کیفیت جملات را در نظر می‌گیرد و دسته‌ای دیگر فقط تنوع جملات تولیدی را ارزیابی می‌کنند. این موضوع باعث می‌شود که مقایسه‌ی دو مدل به راحتی میسر نشود. در این فصل علاوه بر تشریح معیارهای پیشین، چهار معیار جدید معرفی شده است.  دو مورد از این معیارها در ارزیابی با داده‌ی مصنوعی 
(بخش 
\ref{Metric:DistanceOracle})
و یک مورد در حوزه‌ی ارزیابی دنباله‌ها از دید 
\ngram{} 
 است 
(بخش
  \ref{Metric:MSJaccard}). 
در آخر معیاری خاص دنباله‌های زبان طبیعی پیشنهاد شده (
 بخش
   \ref{Metric:FBD})
 که براساس معیاری معتبر در حوزه‌ی ارزیابی تصاویر بنا نهاده شده است.
 
 
لازم به ذکر است که معیار‌های خاص یک حوزه فقط محدود به زبان طبیعی نیست.
 برای مثال دنباله‌هایی که روی ساختار مولکولی هستند، می‌توان با خواص شیمیایی مثل پایداری آن، ارزیابی شود. حتی این ارزیابی می‌تواند محاسباتی برای شبیه‌سازی رفتار ساختار تولید شده باشد. یا به عنوان مثالی دیگر، برای دنباله‌های نت موسیقی می‌توان با خبرگی معیارهای برای طبیعی بودن آن تعریف کرد
 \cite{ORGAN}.
\newline
برای مشخص شدن معیار‌های معرفی شده در این پژوهش، عنوان بخش‌های مربوط به معیار پیشنهادی با پیشوند «معیار پیشنهادی» مشخص شده‌اند.
% \newpage
\section{معیا‌رهای مبتنی بر احتمال مدل}
قدیمی‌ترین معیار مورد استفاده معیار‌هایی بوده که بر اساس درست‌نمایی مدل بنا نهاده شده است، این معیار‌ مشکلاتی دارد.
بزرگترین مشکل این معیار در ارزیابی روش‌های جدید ناعادلانه بودن آن است، زیرا مدل پایه این معیار را به عنوان تابع هدف در نظر می‌گیرد و کمینه می‌کند. از این  رو، قرار دادن این معیار به عنوان مبنای قضاوت به مقایسه‌ای عادلانه منجر نمی‌شود.
در ادامه دو معیار معروف از این دسته معرفی شده است و مشکلات آن به صورت جزئی مورد بررسی قرار می‌گیرد.
\subsection{منفی لگاریتم درست‌نمایی}\label{Metric:NLLModel}
معیار
\trans{منفی لگاریتم درست‌نمایی}{Negative Log Likelihood}
که به اختصار
\lr{NLL}
می‌نامیم، فقط برای مدل‌های احتمالی قابل استفاده است؛ یعنی باید بتوان احتمالی که مدل به دنباله می‌دهد را محاسبه کرد. معیار  منفی لگاریتم درست‌نمایی 
برابر منفی لگاریتم میزان احتمالی است که مدل به داده‌های واقعی می‌دهد؛ بنابراین کمتر بودن آن به معنی نتیجه‌ی بهتر است.
این معیار به صورت زیر تعریف می‌شود:
\begin{equation}
\text{NLL} = - \frac{1}{N} \sum_{n=1}^N \log  q(x^{(n)}),
\end{equation}
که $q(x)$ بیانگر احتمالی است که مدل به نمونه‌ی $x$ می‌دهد و  $x^{(n)}$  نمونه‌هایی است که از توزیع اصلی در اختیار داریم.

مشکلاتی برای این معیار وجود دارد که به شرح زیر است:
\begin{itemize}
	\item
	فقط برای مدل‌های احتمالی قابل استفاده است.
	\item 
	این معیار در روش‌های تولید دنباله که با کمک قاعده‌ی زنجیره‌ای دنباله‌ها را مدل می‌کنند  حساسیتی نسبت به مشکل اُریبی مواجهه 
	(بخش \ref{Method:TeacherForcing})
	ندارد. زیرا برای محاسبه‌ی این معیار همواره نمونه‌هایی از داده‌ واقعی وارد مدل شده و توزیع احتمال شرطی به شرط دنباله‌ی صحیح بررسی می‌شود.
	از این رو روش‌هایی که مدعی برطرف کردن مشکل اُریبی مواجهه	هستند، به این معیار اهمیت کمتری می‌دهند. 
	\item 
	مشکلی دیگری که وجود دارد امتیاز پایینی است که این معیار به روش‌هایی با رفتار میانگین-جستجوگری	می‌دهد. در نظر بگیرید که یک مدل آموزش دیده و به اکثر داده‌های واقعی احتمال بالایی نسبت داده ولی به بخش کوچکی از داده‌های واقعی احتمالا نزدیک صفر نسبت دهد. در این حالت معیار منفی لگاریتم درست‌نمایی حاصل جمع عباراتی است که یکی از این عبارات به مثبت بی‌نهایت میل می‌کند و اثر بقیه جملات از بین می‌رود. به همین دلیل ممکن است امتیاز مدل آموزش دیده که بخشی از توزیع واقعی را آموزش دیده از مدلی که تصادفی به تمام جملات احتمال یکسان می‌دهد کمتر شود.
	به بیان دیگر، در عمل عبارت
	$\log \prod_{x_i} q(x_i)$
	برای محاسبه‌ی معیار محاسبه می‌شود، که با نزدیک به صفر شدن یکی از $q(x_i)$ ها کل مقدار سمت راست تساوی  به سمت صفر می‌رود.
	\item
	این معیار خود تابع هزینه‌ی بعضی از روش‌ها است؛ بنابراین مقایسه روش‌هایی که این تابع هزینه را به عنوان هزینه در نظر می‌گیرند، در مقابل روش‌هایی که از این تابع هزینه استفاده نمی‌کنند (مثل شبکه‌های مولد مقابله‌ای) غیرعادلانه است.
\end{itemize}

\subsection{\lr{Perplexity}}\label{Metric:PPModel}
\temptext{این ترجمش چیه}
این معیار کاملا مشابه معیار منفی لگاریتم درست‌نمایی است، با این تفات که به‌نوعی رفتار لگاریتمی آن حذف شده است. این معیار در حالت عادی به صورت زیر تعریف می‌شود:
		\begin{equation}\label{Ch4:Equation:PerplexityDefinition}
		\text{PP} = b^{- \frac{1}{N} \sum_{n=1}^N \log_b  q(x^{(n)})},
		\end{equation}
		که معمولا $b$ یکی از مقادیر $2$ یا $e$ است.
		\newline
		اگر در رابطه‌ی 
		\ref{Ch4:Equation:PerplexityDefinition}
		به جای $N$ که تعداد نمونه‌ها (دنباله‌ها) را نشان می‌دهد، تعداد کلمات کل دنباله‌های جایگذاری شود و نسبت به تعداد کلمات نرمال شود، آنگاه معیار حاصل
		\lr{Perplexity Per Word}
		نام دارد.
\section{معیارهای مبتنی بر داده‌ی مصنوعی  }
این دسته از معیارها برای سنجش آموزش بر روی مجموعه داده‌ی واقعی که در اختیار داریم قابل استفاده نیستند. این معیارها فقط برای مقایسه‌ی مدل‌ها در مقابل همدیگر کاربرد دارد. در این روش ارزیابی، داده‌های مصنوعی تولید می‌شود که ویژگی‌های آن را به خوبی می‌دانیم و با آموزش مدل‌ها بر روی این داده‌ها، کیفیت مدل آموزش دیده بررسی می‌شود. در ادامه چند نمونه از این معیار‌های ارزیابی بیان شده است.
\subsection{منفی لگاریتم درست‌نمایی پیشگو}\label{Metric:NLLOracle}
این روش ارزیابی یکی از پراستفاده‌ترین روش‌ها در بررسی مدل‌های مولد دنباله است.
در این معیار، برای تولید داده‌های مصنوعی توزیع احتمالی به صورت تصادفی می‌سازیم؛ با نمونه گیری از این توزیع، داده‌های مصنوعی ساخته می‌شود. در حوزه‌ی دنباله یکی از راهکارهای ساخت توزیع احتمال در نظر گرفتن شبکه‌ی عصبی با مقادیر پارامتر تصادفی به عنوان توزیع هدف است. در مقاله‌ی 
\cite{SeqGAN}
از یک شبکه‌ی
\lr{LSTM}
با مقادیر پارامتر تصادفی استفاده می‌شود؛ آن توزیع را،
\trans{پیشگو}{Oracle}
می‌نامیم.
بعد از آموزش مدل به‌وسیله‌ی داده‌های مصنوعی، ارزیابی به این صورت انجام می‌شود که تعدادی داده‌ با نمونه‌گیری از مدل به دست می‌آید؛ داده‌های تولید شده به شبکه‌ی پیشگوی ورودی داده می‌شود و به‌وسیله‌ی آن مقدار 
$p(x)$
محاسبه می‌شود. با کمک پیشگو، درست‌نمایی داده‌های تولیدی از نظر پیشگو محاسبه می‌شود و به عنوان معیار در نظر گرفته می‌شود:
\begin{equation}
\text{NLL-Oracle} = - \ME_{x \sim Q} \log p(x),
\end{equation}
که این معیار منفی لگاریتم درست‌نمایی پیشگو یا به اختصار
\lr{NLL-Oracle}
نامیده می‌شود.
\newline
از مشکلات این  معیار عدم توجه به تنوع نمونه‌های تولید شده توسط مدل است. به این صورت که اگر مدل فقط یک نمونه تولید کند و آن یک نمونه، نمونه‌ی با کیفیتی از دید پیشگو باشد، امتیاز مدل بسیار بالا می‌شود؛ در حالی که چنین مدلی مطلوب نیست.
اشکال دیگری که به این روش وارد است، در رابطه با نحوه‌ی ساخت توزیع پیشگو است. زمانی که توزیع پیشگو با شبکه‌ی
\lr{LSTM}
تصادفی ساخته می‌شود، کنترلی بر روی پیچیدگی دنباله‌های تولید شده وجود ندارد
\cite{subramanian2017adversarial}.
\subsection{معیار پیشنهادی - فاصله با پیشگو }\label{Metric:DistanceOracle}
همانطور که گفته شد در مقالات حوزه‌ی تولید دنباله معیار درست‌نمایی پیشگو پراستفاده است؛ در حالی که این معیار با در نظر نگرفتن تنوع داده‌ی تولیدی می‌تواند اشکالاتی جدی ایجاد کند. مثلا احتمال بروز مشکل ‌  چسبیدگی به قله  در شبکه‌های مولد مقابله‌ای زیاد است و اگر این اتفاق روی دهد، این معیار نه تنها جریمه‌ای نمی‌کند بلکه امتیاز بالایی نسبت می‌دهد.
\newline
در بیشتر روش‌ها، مدل مولد خود یک مدل احتمالی است و روش منفی لگاریتم درست‌نمایی پیشگو از این موضوع سودی نمی‌برد.
در این پژوهش استفاده از فاصله‌های متقارن بین مدل آموزش دیده و  پیشگو، برای ارزیابی مدل پیشنهاد می‌کنیم. در واقع زمانی که دو مدل احتمالی در اختیار داریم طیف وسیعی از فاصله‌ها قابل تخمین است.
دو فاصله‌ی
\lr{Bhattacharyya}
و
\lr{Jeffrey}
برای این منظور انتخاب شده است، زیرا با بررسی‌های که انجام شد تخمین با خطای کمتری داشته‌اند.
\newline
بنابراین نحوه‌ی ارزیابی به این صورت است که بعد از ایجاد یک  پیشگو با توزیع  احتمال تصادفی مشابه بخش 
\ref{Metric:NLLOracle}،
از توزیع تصادفی به دست آمده نمونه‌گیری می‌شود و داده‌های‌ آموزش به دست می‌آید.  سپس با داده‌ها‌ی به دست آمده، مدل آموزش داده می‌شود و در نهایت با در اختیار داشتن هر دو مدل احتمالی مولد و پیشگو، فاصله‌ی بین این دو به صورت تقریبی محاسبه می‌شود. در ادامه دو فاصله و نحوه‌ی تخمین آن بیان شده است.
\subsubsection{فاصله‌ی \lr{Bhattacharyya}}
این فاصله به صورت زیر تعریف می‌شود:
\begin{equation}
\begin{split}
\mathfrak{D}_{BC}( P \parallel Q) &= - \ln BC(P,Q)\\
BC(P,Q) &= \sum _{{x\in X}}{\sqrt  {p(x)q(x)}}.
\end{split}
\end{equation}
برای تخمین این فاصله، آن را به فرم امید می‌بریم:
\begin{equation}\label{Ch4:Equation:BC:ExpectedForm1}
\begin{split}
BC(P,Q) &= \sum _{x\in X}{\sqrt  {p(x)q(x)}}\\
 &= \sum _{x\in X}{\sqrt  {p(x)q(x) \frac{p(x)}{p(x)}}}\\
  &= \sum _{x\in X}{p(x) \sqrt  {\frac{q(x)}{p(x)}}}\\
  &= \ME _{x\sim P}{\sqrt  {\frac{q(x)}{p(x)}}}.
\end{split}
\end{equation}
به صورت مشابه، داریم:
\begin{equation}\label{Ch4:Equation:BC:ExpectedForm2}
\begin{split}
BC(P,Q) &= \sum _{x\in X}{\sqrt  {p(x)q(x)}}\\
&= \sum _{x\in X}{\sqrt  {p(x)q(x) \frac{q(x)}{q(x)}}}\\
&= \sum _{x\in X}{q(x) \sqrt  {\frac{p(x)}{q(x)}}}\\
&= \ME _{x\sim Q}{\sqrt  {\frac{p(x)}{q(x)}}}.
\end{split}
\end{equation}
با توجه به روابط
\ref{Ch4:Equation:BC:ExpectedForm1}
و
\ref{Ch4:Equation:BC:ExpectedForm2}
تخمین‌گر زیر به دست می‌آید:
\begin{equation}
    \label{Ch4:Equation:BC:Estimator}
   \mathfrak{D}_{BC}( P \parallel Q) \approx
   - \frac{1}{2} \Big(
   \ln \frac{1}{N} \sum_{i=1}^N \sqrt{\frac{q(x^{(i)})}{p(x^{(i)})}} 
    +\ln \frac{1}{M} \sum_{j=1}^M \sqrt{\frac{p(x^{(j)})}{q(x^{(j)})}}
    \Big),
\end{equation}
که 
$x^{(i)}$ها
نمونه‌هایی از توزیع
$P$
و
$x^{(j)}$ها
نمونه‌هایی از توزیع
$Q$
است.
\subsubsection{فاصله‌ی \lr{Jeffrey}}
این فاصله به صورت زیر تعریف می‌شود:
\begin{equation}
\mathfrak{D}_{J}( P \parallel Q)=\sum _{{x\in X}} (p(x)-q(x)){\big (}\ln p(x)-\ln q(x){\big )}.
\end{equation}
برای این فاصله تخمین‌گر زیر را داریم:
\begin{equation}
\begin{split}
\mathfrak{D}_{J}( P \parallel Q) &= \sum _{{x\in X}} (p(x)-q(x)){\big (}\ln p(x)-\ln q(x){\big )}\\
 &= \sum _{{x\in X}} p(x) \ln \frac{p(x)}{q(x)}
- \sum _{{x\in X}} q(x) \ln \frac{p(x)}{q(x)}\\
 &= \ME_{x \sim P} \ln \frac{p(x)}{q(x)}
 - \ME_{x \sim Q}\ln \frac{p(x)}{q(x)}\\
  &= \ME_{x \sim P} \ln \frac{p(x)}{q(x)}
  + \ME_{x \sim Q}\ln \frac{q(x)}{p(x)}\\
 \Rightarrow \mathfrak{D}_{J}( P \parallel Q) &\approx  
 \frac{1}{N}\sum_{i=1}^N \ln \frac{p(x^{(i)})}{q(x^{(i)})}
  + \frac{1}{M}\sum_{j=1}^M \ln \frac{q(x^{(j)})}{p(x^{(j)})},
\end{split}
\end{equation}
که 
$x^{(i)}$ها
نمونه‌هایی از توزیع
$P$
و
$x^{(j)}$ها
نمونه‌هایی از توزیع
$Q$
است.
\subsection{گرامر مستقل از متن}\label{Metric:CFG}
در برخی پژوهش‌ها
	\cite{kusner2016gans,subramanian2017adversarial}،
	برای بررسی قدرت مدل و اینکه چقدر ساختار‌های دنباله را یاد گرفته است از یک 
		\trans{گرامر مستقل از متن}{Context Free Grammar}
	 استفاده می‌شود.
	به این صورت که با تعریف گرامری از این نوع، زبانی تعریف می‌شود. با ساخت دنباله‌هایی از این زبان داده‌های آموزش مصنوعی تولید شده و مدل با آن آموزش می‌بیند. از مدل آموزش دیده نمونه‌هایی تولید می‌شود و درصد قبول شدن این نمونه‌ها در گرامر به عنوان معیار در نظر گرفته می‌شود. 
	در این روش می‌توان با تعریف گرامر‌های مختلف، سطوح مختلف پیچیدگی دنباله‌ها را ایجاد کرد.
\section{ معیارهای مبتنی بر \ngram}
این معیار مناسب دنباله‌هایی مثل زبان‌های طبیعی است که الگو‌های محلی غنی دارند.
باوجود اینکه این معیارها برای زبان‌های طبیعی پراستفاده است ولی معنای جملات را در نظر نمی‌گیرند و فقط به بررسی
\ngram
های زبان می‌پردازد. منظور از 
\ngram{}
زیر دنباله‌های $n$ تایی یک دنباله است.
\newline
در این بخش ابتدا دو معیار مورد استفاده در پژوهش‌های پیشین و مشکلات آن‌ها را تشریح کرده، سپس معیار جدیدی که در این پژوهش معرفی شده است، را بیان می‌کنیم. با معیار جدید سعی بر رفع مشکلات دو معیار پیشین داشته‌ایم.
\temptext{میشه در مورد معیار invers bleu هم صحبت کرد}
\subsection{\lr{BLEU}}\label{Metric:BLEU}
معروف‌ترین معیار بر حسب 
\ngram ها
معیار
\lr{BLEU}
است؛ این معیار در اصل در حوزه‌ی  ترجمه زبان پیشنهاد شده و 
صحت این معیار، در ارزیابی ترجمه اثبات شده است. با ارزیابی انسانی مشخص شده که 
\lr{BLEU}
\trans{همبستگی}{Correlation}
زیادی با قضاوت انسانی دارد
\cite{papineni2002bleu}.
در معیار 
\lr{BLEU}
هدف محاسبه‌ی کیفیت ترجمه براساس چند متن مرجع است. در این ارزیابی برای هر جمله در زبان مبدا، چندین جمله در زبان مقصد وجود دارد. پس از ترجمه متن به زبان مقصد، این ترجمه با معیار
\lr{BLEU}
بر اساس مجموعه‌ای از جملات که در زبان مقصد در اختیار داریم ارزیابی می‌شود. این ارزیابی بر اساس شباهت
\ngram های
حاصل ترجمه و جملات نمونه در زبان مقصد است و مقداری بین صفر و یک دارد؛ افزایش آن به معنی شباهت بیشتر است.
\newline
این معیار در حوزه‌ی ارزیابی تولید متن‌های تولید شده  استفاده زیادی داشته است؛ به این صورت که مجموعه‌ای از داده‌های اصلی (بجای مجموعه متن مرجع در ترجمه)
به عنوان مرجع در نظر گرفته می‌شود و متن تولیدی بر اساس این مرجع ارزیابی می‌شود.
این معیار بیشتر برای دنباله‌های زبان طبیعی کاربرد دارد، ولی برای دیگر دنباله‌ها نیز قابل استفاده است.
\newline
از مشکلات این معیار در بررسی متن تولیدی علاوه بر محدود بودن به بررسی الگوهای محلی، تاثیرپذیری این معیار از اندازه‌ی مجموعه مرجع است
\cite{papineni2002bleu}.
 این حساسیت باعث می‌شود در مقایسه‌ی دو روش طبق این معیار، نیاز باشد اندازه‌ی مجموعه مرجع یکسان باشد. مشکل دیگر این ارزیابی عدم توجه به تنوع نمونه‌های تولید شده توسط مدل است. به این صورت که اگر مدل فقط یک نمونه تولید کند و آن یک نمونه، نمونه‌ی با کیفیتی از دید معیار باشد،؛ آنگاه امتیاز مدل بسیار بالا می‌رود، در حالی که چنین مدلی مطلوب نیست.
\newline
در ادامه به نحوه‌ی محاسبه
\lr{BLEU}
که در
\cite{papineni2002bleu}
ارائه شده، برای محاسبه‌ی امتیاز یک تک جمله می‌پردازیم. برای ارزیابی جملات تولید شده، پس از محاسبه‌ی امتیاز
\lr{BLEU}
مربوط به تک تک جملات برای تجمیع این امتیاز‌ها از میانگین حسابی استفاده می‌شود\footnote{در مقاله‌ی اصلی  
	\lr{BLEU}
	\cite{papineni2002bleu}
	که در حوزه‌ی ترجمه است، 	راهکاری دیگر برای  حالت چند جمله معرفی شده است؛ ولی این راهکار در ارزیابی‌ روش‌های تولید دنباله استفاده نمی‌شود.}.
\subsubsection{نحوه‌ی محاسبه‌ی \lr{BLEU}}
این معیار بر حسب شباهت‌های
\ngram{}
جمله‌ی مورد بررسی و جملات مرجع کار می‌کند. ابتدا معیار را برای یک $n$ خاص بررسی می‌کنیم و سپس نحوه‌ی امتیازدهی نهایی بیان می‌شود.
\newline
 این معیار
\ngram
های جمله‌ی مورد بررسی را با مجموعه‌ی
\ngram
های موجود در جملات مرجع را به صورت یک به یک جفت می‌کند و نسبتی از
\ngram
های جمله‌ی مورد بررسی که با 
\ngram
های جملات مرجع یکی می‌شود را امتیاز برای حالت $n$ در نظر می‌گیرد؛
 ولی محدودیتی وجود دارد که برای هر
\ngram{}
فقط یک جمله (بهترین جمله) از مجموعه مرجع استفاده می‌شود. یعنی حداکثر تعداد جفت شدن‌های یک
\ngram{}
که با $x$ نشان می‌دهیم، برابر
$ \displaystyle \max_i \{Count_n(r_i,x)\}$
است که
$Count_n(r_i,x)$
به معنی تعداد تکرار 
\ngram{}
$x$
در  جمله‌ی مرجع $i$ ام است.
به صورت دقیقتر امتیاز برای یک $n$ خاص برای جمله‌ی مورد بررسی $s$ به صورت زیر محاسبه می‌شود.
\begin{equation}\label{Ch4:Equation:BLEU:PnDefinition}
p_n = \frac
{\sum_{x \in G_n} \min\Big(Count_n(s,x),\max\limits_{i} \{Count_n(r_i,x)\}\Big)}
{\sum_{x \in G_n} Count_n(s,x)},
\end{equation}
که مجموعه‌ی
 $G_n$
تمام
\ngram های
ممکن و
$Count_n(x,y)$
به معنی تعداد تکرار 
\ngram{}
$y$
در جمله‌ی $x$  است.
در رابطه
\ref{Ch4:Equation:BLEU:PnDefinition}
مخرج کسر در واقع تعداد
\ngram
های جمله‌ی مورد بررسی است.
\newline
بری تجمیع امتیازها به ازای $n$ های مختلف و به دست آوردن یک عدد برای جمله‌ی مورد بررسی، از میانگین هندسی $p_n$ ها استفاده می‌شود؛ زیرا $p_n$ نسبت به $n$ به صورت نمایی کاهش می‌یابد. میانگین هندسی $p_n$ برابر میانگین حسابی
$\log \; p_n$
است.
\newline
در معیاری که تا به اینجا گفته شده است،
جملات طولانی‌تر از مرجع بدلیل بررسی 
\ngram
های آن در صورت بد بودن جریمه می‌شوند؛ ولی جملات کوچک می‌توانند به نادرست امتیاز بالایی بگیرند. بنابراین با اعمال تاثیر طول جمله‌ی مورد بررسی معیار
\lr{BLEU}
 محاسبه می‌شود.
برای آنکه جملات کوچکتر از مرجع  امتیاز نادرست و زیاد نگیرند، تاثیر طول جملات تولید شده به صورت ضریبی در معیار اضافه می‌شود. به این صورت که جملات که جمله‌ی هم‌اندازه‌ و یا کوچکتر در مرجع دارند تغییری نمی‌کنند و جملات که از مرجع کوچکتر هستند، جریمه می‌شوند.
 برای حالتی که
\ngram
های با  $n$ برابر $1$ تا $N$ دارند، لگاریتم معیار
\lr{BLEU}
به صورت زیر می‌شود
\cite{papineni2002bleu}:
\begin{equation}
\min(0, 1 - \frac{l_s}{l_r}) + \frac{1}{N} \sum_{n=1}^{N} \log P_n ,
\end{equation}
که 
$l_s$ 
و
$l_r$
به ترتیب طول جمله مورد بررسی و طول نزدیکترین جمله 
\footnote{طبق کد کتابخانه‌ی 
	\href{https://www.nltk.org/_modules/nltk/translate/bleu_score.html}{NLTK}
	در حالتی که دو جمله هم فاصله وجود دارد، جمله‌ی با طول کمتر انتخاب می‌شود.
	}
در مرجع به جمله‌ی مورد بررسی است. در حالتی که جمله هم‌طول در مجموعه مرجع وجود دارد، تساوی
$\min(0, 1 - \frac{l_s}{l_r}) = 0 $
برقرار است و تاثیری در امتیاز محاسبه شده توسط
\ngram
ها نمی‌گذارد. 
\subsection{\lr{Self-BLEU}}\label{Metric:SelfBLEU}
همانطور که اشاره شده معیار
\lr{BLEU}
از تنوع نمونه‌های تولید شده توسط مدل تاثیری نمی‌پذیرد، از این رو در
\cite{zhu2018texygen}
معیاری معرفی شده است که بصورت جدا گانه فقط تنوع نمونه‌های تولید شده را بررسی می‌کند.
\newline
این معیار بر اساس 
\lr{BLEU}
است و برای محاسبه‌ی آن، هر یک از جملات تولیدی را به عنوان جمله‌ی مورد بررسی در نظر گرفته و باقی‌ جملات را به عنوان مرجع در نظر می‌گیرد؛ سپس معیار
\lr{BLEU}
را در هر حالت محاسبه کرده و میانگین این امتیاز‌ها به عنوان 
\lr{Self-BLEU}
تعریف می‌شود. کم بودن این معیار بیانگر تنوع بیشتر جملات تولیدی است، در بهترین حالت این مقدار صفر و بدترین مقدار آن یک است.

\subsection{معیار پیشنهادی - \lr{MS-Jaccard} }\label{Metric:MSJaccard}
همان‌طور که در بخش‌های قبل گفته شد، معیار
\lr{BLEU}
فقط کیفیت را در نظر گرفته و تنوع را در نظر نمی‌گیرد؛ از سمت دیگر معیار
\lr{Self-BLEU}
کیفیت را در نظر نمی‌گیرد و تنوع را فقط در نظر می‌گیرد. در این بخش معیاری جدید را مبتنی بر
\ngram{}
معرفی می‌کنیم، که به صورت همزمان تنوع و کیفیت را در نظر بگیرد. معیار پیشنهادی
\lr{MS-Jaccard}
نام دارد.
\newline
همانطور که گفته شد، معیار
\lr{BLEU}
تک تک جملات تولید شده را  با کل مجموعه‌ی مرجع مقایسه کرده و سپس میانگین‌ امتیاز‌ها را استفاده می‌کند. در مقابل روش پیشنهادی کل جملات تولید شده را همزمان با کل جملات مرجع مقایسه می‌کند تا همزمان کیفیت و تنوع جملات سنجیده شود. برای محاسبه‌ی معیار همه‌ی 
\ngram
های جملات تولید شده را به عنوان یک
\trans{چند‌مجموعه}{Multiset}
(یعنی یک 
\ngram{}
 می‌تواند چند بار تکرار شود) و 
\ngram
های جملات مجموعه مرجع را به عنوان چند‌مجموعه‌ای دیگر در نظر گرفته؛ فاصله‌ی
\lr{Jaccard}
این دو چندمجموعه مبنا‌ی معیار
\lr{MS-Jaccard}
است. به ازای یک $n$ خاص، امتیاز معیار به صورت زیر است:
\begin{equation}\label{Eq:metric:MSJ}
p_n = \frac
{\sum_{x \in S_1 \cup S_2} \min\{Count_n(S_1,x), Count_n(S_2,x)\} }
{\sum_{x \in S_1 \cup S_2} \max\{Count_n(S_1,x), Count_n(S_2,x)\} },
\end{equation}
که $S_1$ و $S_2$ به ترتیب نشان دهنده‌ی چندمجوعه‌ی شامل 
\ngram
های جملات تولیدی و جملات مرجع است. تابع 
$Count_n(S,x)$
به معنی تعداد
\ngram{}
$x$
در چندمجموعه‌ی $S$ است.
\newline
از آنجا که این معیار بسته به اندازه‌ی مجموعه‌ها وابسته است، برای رفع این مشکل تابع
$Count_n(S,x)$
را بازتعریف می‌کنیم و آن را به معنی نسبت
\ngram{}
$x$
به کل تعداد در چندمجموعه‌ی $S$ در نظر می‌گیریم. در نهایت معیار
\lr{MS-Jaccard}
میانگین هندسی امتیازهای $p_n$ برای $n$ برابر $1$ تا $N$ است.
\newline
این معیار مقداری بین صفر و یک دارد، افزایش آن به معنی نزدیک شدن جملات تولیدی به جملات مرجع است.


دلیلی که باعث می‌شود معیار
 ‎\lr{MS-Jaccard}
 تنوع دنباله‌ها را نیز در نظر بگیرد این است که دنباله‌های مرجع تنوعی ذاتی در خود دارند و  این معیار فاصله‌ای بین نمونه‌های تولید شده و نمونه‌های مرجع محاسبه می‌کند. به همین دلیل تنوعی مشابه با داده‌های مرجع  مقادیر بهتری در معیار دارد. برای مثال اگر یک
 ‎\ngram{}
    در نمونه‌های تولیدی از نمونه‌های مرجع بیشتر شود، آنگاه در صورت کسر
 \ref{Eq:metric:MSJ}
مقدار اثر گذار برابر تعداد تکرار
 ‎\ngram{}
   در نمونه‌های مرجع است و مقدار اثر گذار در  مخرج کسر با تعداد
 ‎\ngram{}
    در نمونه‌های تولید شده زیاد می‌شود و باعث کاهش مقدار معیار می‌شود. به همین صورت کاهش تعداد 
‎ \ngram{}
     نسبت به نمونه‌های مرجع باعث کاهش صورت کسر می‌شود  و صورت ثابت می‌ماند، در نتیجه معیار کم می‌شود.

\section{ معیار پیشنهادی - \lr{Fr\'echet BERT Distanc‌e} }\label{Metric:FBD}
معیار 
\lr{Fr\'echet BERT Distance (FBD)}
که در این پژوهش معرفی شده است، مربوط به حوزه‌ی زبان‌های طبیعی است و بیشترین کیفیت را در زبان انگلیسی دارد.
در ابتدا معیار
\lr{Fr\'echet Inception Distance (FID)}\cite{heusel2017gans}
و شبکه‌ی عمیق
\trans{برت}{BERT}\cite{devlin2018bert}
که پایه‌های این معیار است، معرفی می‌شود؛ سپس به تشریح معیار
\lr{FBD}
می‌پردازیم.
\newline
مشکل ارزیابی نتایج مدل‌های مولد، تنها محدود به حوزه‌ی دنباله نیست. روش‌های مولد تصویر نیز در ارزیابی خود چالش دارند و برای رفع آن پژوهش‌های زیادی شده است. معیار پراستفاده و جدیدی که در این حوزه وجود دارد،
\lr{FID}
است.
معیار
\lr{FID}
بر اساس ویژگی‌هایی که از شبکه‌ی عمیق
\lr{Inception}
استخراج می‌شود، کار می‌کند. این شبکه یکی از معروف‌ترین دسته‌بندهای حوزه‌ی تصویر است. معیار
\lr{FID}
در ابتدا با کمک شبکه‌ی 
\lr{Inception}
تصاویر مورد ارزیابی را به فضای ویژگی می‌برد، سپس در این فضا فاصله‌ی توزیع نمونه‌های آزمون و نمونه‌های تولید شده را محاسبه کرده و به عنوان معیار در نظر می‌گیرد.
برای محاسبه‌ی فاصله توزیع نمونه‌های آزمون و نمونه‌های تولید شده، برای هر کدام یک توزیع گاوسی فرض می‌شود و فاصله‌ای که بین این دو توزیع محاسبه می‌شود، براساس فاصله‌ی
\lr{Fr\'echet}
است. فاصله‌ی
\lr{Fr\'echet}
که به نام
\lr{Wasserstein-2}
هم شناخته می‌شود، در حالت کلی قابل محاسبه به فرم بسته نیست؛ ولی در اینجا چون با تقریب دو توزیع گاوسی فرض شده است، فاصله به صورت زیر قابل محاسبه است:
\begin{equation}
{||m_1-m_2||}_2^2 + Tr( C_1 + C_2 -2(C_1C_2)^{1/2}),
\end{equation}
که $m_i$ و $C_i$  به ترتیب میانگین و کواریانس توزیع‌ها را نشان می‌دهند.
\newline
تا چندی پیش در حوزه‌ی زبان طبیعی، شبکه‌ا‌ی به قدرت
\lr{Inception}
وجود نداشت. 
ولی به‌تازگی شبکه‌ای توسط شرکت گوگل بر روی کل متون ویکی‌پدیا آموزش دیده و منتشر شده است. این شبکه که برت نام دارد، یک شبکه‌ی عمیق و پر قدرت است که آموزش آن نیاز به چندین ماه محاسبه توسط کارت گرافیک دارد. شبکه‌ی برت توانسته در بسیاری چالش‌های حوزه‌ی متن زبان طبیعی  نتایج مرز دانش را کسب کند
\cite{devlin2018bert}.
از آنجا که شبکه‌های آموزش دیده‌ی برت بر روی بیشتر زبان‌ها به صورت عمومی منتشر شده است\LTRfootnote{\href{https://github.com/google-research/bert}{https://github.com/google-research/bert}}،
می‌توان از آن به جای شبکه‌ی
\lr{Incpetion}
در معیار 
\lr{FID}
استفاده کرد و معیاری در حوزه‌ی زبان‌های طبیعی داشت.
\newline
بنابراین معیار 
\lr{FBD}
را به این صورت تعریف می‌کنیم که ابتدا جملات تولید شده و جملات آزمون با استفاده از شبکه‌ی برت به فضای ویژگی برده می‌شوند؛ سپس با محاسبه‌ی میانگین و کواریانس هر کدام از این دو مجموعه داده، فاصله‌ی 
\lr{Fr\'echet}
بین آنها محاسبه می‌شود.
\section{جمع‌بندی}
در این بخش معیار‌های پیشین و معیار‌های پیشنهادی در قالب جدول
\ref{Table:MetricSummary}
جمع بندی شده است.
لازم به ذکر است که  معیار‌های مشخص شده با ستاره، برای ارزیابی مدل مولد دنباله، در این پژوهش معرفی شده‌اند.
\begin{table}[!htb]
	\footnotesize
	\caption[مقیاسه‌ی معیار‌های موجود و پیشنهاد شده]{مقیاسه‌ی معیار‌های موجود و پیشنهاد شده.
		«مدل احتمالی» بیانگر نیاز به احتمالی بودن مدل است. 
		«تاثیر تنوع» به معنی در نظر گرفتن تنوع دنباله‌های تولید شده از نظر معیار است.
		«تاثیر کیفیت» به معنی در نظر گرفتن کیفیت دنباله‌های تولید شده از دید معیار است.
		«تاثیر اُریبی مواجهه» به معنی تاثیر پذیری معیار از وجود این مشکل است.
		«سمت بهبود» به معنی جهتی است که در آن جمت تغییر معیار مطلوب است. 
		«بازه» نشان دهنده‌ی بازه‌ی ممکن برای معیار است. $H$ به معنی 
		\trans{آنتروپی}{Entropy}
		داده‌های آموزش است.
		معیار‌های مشخص شده با ستاره، برای ارزیابی مدل مولد دنباله، در این پژوهش معرفی شده‌اند.
	}
	\label{Table:MetricSummary}
	\centering
	\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|}
		\hline
		
		دسته
		&
		نام مختصر
		&
		 نام کامل
		&
		\begin{tabular}{@{}c@{}} بخش \\ مرتبط\end{tabular}
		& 
		\begin{tabular}{@{}c@{}} مدل \\ احتمالی\end{tabular}
		& 
		\begin{tabular}{@{}c@{}} تاثیر \\ تنوع\end{tabular}
		&
		\begin{tabular}{@{}c@{}} تاثیر \\ کیفیت\end{tabular}
		&
		\begin{tabular}{@{}c@{}}
			تاثیر اُریبی ‎\\‎
			مواجهه 
		\end{tabular}
		& 
		\begin{tabular}{@{}c@{}} 
			جهت \\
			 بهبود
		\end{tabular}
		&
		بازه      
		\\ \hline
		\multirow{2}{*}{\begin{tabular}{@{}c@{}} مبتنی بر \\ احتمال\\ مدل \end{tabular}}            & \lr{NLL-Model}  &
		\begin{tabular}{@{}c@{}}   منفی لگاریتم  \\ درست‌نمایی \\مدل  \end{tabular}  & \ref{Metric:NLLModel}       & $\boldsymbol{*}$ & $\boldsymbol{*}$ & $\boldsymbol{*}$ & &$\downarrow$ & $H$ تا $\infty$   \\ \cline{2-10} 
		
		& \lr{PP}     & \lr{Perplexity}       & \ref{Metric:PPModel}        & $\boldsymbol{*}$ & $\boldsymbol{*}$ & $\boldsymbol{*}$ &
		& $\downarrow$ & $b^H$ تا $\infty$ \\ \hline
		\multirow{4}{*}{\begin{tabular}{@{}c@{}}  \\ مبتنی بر \\ داده‌ی \\مصنوعی\end{tabular}}         & \lr{NLL-Oracle}  &
		\begin{tabular}{@{}c@{}} منفی لگاریتم  \\ درست‌نمایی \\پیشگو  \end{tabular}
		& \ref{Metric:NLLOracle}      &                  &                  & $\boldsymbol{*}$ & $\boldsymbol{*}$&$\downarrow$ & $H$ تا $\infty$   \\ \cline{2-10} 
		
		& \lr{Bhattacharyya}\textsuperscript{*} & \lr{Bhattacharyya}& \ref{Metric:DistanceOracle} & $\boldsymbol{*}$ & $\boldsymbol{*}$ & $\boldsymbol{*}$ &$\boldsymbol{*}$& $\downarrow$ & $0$ تا $\infty$   \\ \cline{2-10} 
		
		& \lr{Jeffrey}\textsuperscript{*}   &  \lr{Jeffrey}    & \ref{Metric:DistanceOracle} & $\boldsymbol{*}$ & $\boldsymbol{*}$ & $\boldsymbol{*}$ & $\boldsymbol{*}$&$\downarrow$ & $0$ تا $\infty$   \\ \cline{2-10} 
		
		& \lr{CFG} & \begin{tabular}{@{}c@{}} 
			گرامر
			\\
			مستقل از متن
			\end{tabular}           & \ref{Metric:CFG}            &                  &                  & $\boldsymbol{*}$ &$\boldsymbol{*}$& $\uparrow$   & $0$ تا $1$      \\ \hline
		\multirow{3}{*}{\begin{tabular}{@{}c@{}} مبتنی بر \\ \ngram\end{tabular}} & \lr{BL}  & \lr{BLEU}        & \ref{Metric:BLEU}           &                  &                  & $\boldsymbol{*}$ &$\boldsymbol{*}$& $\uparrow$   & $0$ تا $1$      \\ \cline{2-10} 
		
		& \lr{SBL} & \lr{Self-BLEU}         & \ref{Metric:SelfBLEU}       &                  & $\boldsymbol{*}$ &           &       & $\downarrow$ & $0$ تا $1$      \\ \cline{2-10} 
		
		& \lr{MSJ}\textsuperscript{*}   & \lr{MS-Jaccard}        & \ref{Metric:MSJaccard}      &                  & $\boldsymbol{*}$ & 
		$\boldsymbol{*}$ &$\boldsymbol{*}$& $\uparrow$   & $0$ تا $1$      \\ \hline
		
		\begin{tabular}{@{}c@{}} زبان  \\ طبیعی  \end{tabular}
		& ‎\lr{FBD}‎\textsuperscript{*}‎  
		& \begin{tabular}{@{}c@{}}  \lr{Fr\'echet}\\ \lr{BERT} \\ \lr{Distance}  \end{tabular} 
		& ‎\ref{Metric:FBD}‎          &                  & $\boldsymbol{*}$ & $\boldsymbol{*}$ &$\boldsymbol{*}$& $\downarrow$ & $0$ تا $\infty$   \\ \hline
	\end{tabular}
\end{table}

به این ترتیب، در این پژوهش هم برای ارزیابی مبتنی بر داده‌ی مصنوعی، هم برای ارزیابی مبتنی بر 
\ngram{}
 و هم برای ارزیابی زبان طبیعی معیارهایی ارائه کردیم که به طور هم‌زمان تنوع و کیفیت نمونه‌ها را در نظر می‌گیرند.

